{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "F67KsfrB692M"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "U8VO4aQp7A32"
      },
      "outputs": [],
      "source": [
        "from pyspark.context import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sxmZeBvE7RpX",
        "outputId": "a3222086-9348-48c7-ca5a-6a63f3264baf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://192.168.29.138:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f96257cc670>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sql_context = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "sql_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JOFYwDl37VGp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+-----------------+------------------+----------+---------+---------+-----------------+---------+\n",
            "|               Date|               DO|                pH|       ORP|     Cond|     Temp|              WQI|   Status|\n",
            "+-------------------+-----------------+------------------+----------+---------+---------+-----------------+---------+\n",
            "|2019-01-12 15:33:16|9.494212037759977|13.765933596525262|0.14840198|12.954404|17.830261|54.81198760710678|Very Poor|\n",
            "|2019-01-12 15:34:17|9.500406233111164|13.337534775077296| 0.1445036| 8.547796|17.798553|51.48805043895461|Very Poor|\n",
            "|2019-01-12 15:35:18|9.487447743811652|13.198463167914054|0.13437152|16.847918| 17.86493|50.42070179995088|Very Poor|\n",
            "+-------------------+-----------------+------------------+----------+---------+---------+-----------------+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = sql_context.read.csv(\"./sangam.csv\",header=True,inferSchema='True')\n",
        "data.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qBMnaqcQ7VJW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import csv\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6rKJNW8t7VMS",
        "outputId": "1e353a81-9c6b-4ed7-ffb0-ebf4ab680d82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[DO: double, pH: double, ORP: double, Cond: double, Temp: double, WQI: double, Status: string]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=data.drop('Date')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JNRPUDDO7VO8"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "E68OEfcE7VRl"
      },
      "outputs": [],
      "source": [
        "ind = StringIndexer(inputCol = 'Status', outputCol = 'Status_index')\n",
        "data=ind.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "a2H6rsl97VVR"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "numericCols = ['DO', 'pH', 'ORP', 'Cond','Temp','WQI']\n",
        "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tB33te_K7p20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------------+----------+---------+---------+-----------------+---------+------------+--------------------+\n",
            "|               DO|                pH|       ORP|     Cond|     Temp|              WQI|   Status|Status_index|            features|\n",
            "+-----------------+------------------+----------+---------+---------+-----------------+---------+------------+--------------------+\n",
            "|9.494212037759977|13.765933596525262|0.14840198|12.954404|17.830261|54.81198760710678|Very Poor|         2.0|[9.49421203775997...|\n",
            "|9.500406233111164|13.337534775077296| 0.1445036| 8.547796|17.798553|51.48805043895461|Very Poor|         2.0|[9.50040623311116...|\n",
            "|9.487447743811652|13.198463167914054|0.13437152|16.847918| 17.86493|50.42070179995088|Very Poor|         2.0|[9.48744774381165...|\n",
            "|9.486121036332559|12.732116142804621|0.14270854|16.884756|17.871735|  46.901646035597|Very Poor|         2.0|[9.48612103633255...|\n",
            "|9.485210958535616| 13.28446675206912|0.13752413|16.987082|17.876404|51.10465478084165|Very Poor|         2.0|[9.48521095853561...|\n",
            "+-----------------+------------------+----------+---------+---------+-----------------+---------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = assembler.transform(data)\n",
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "cGkhbDbc7p5F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------------+\n",
            "|            features|Status_index|\n",
            "+--------------------+------------+\n",
            "|[9.49421203775997...|         2.0|\n",
            "|[9.50040623311116...|         2.0|\n",
            "|[9.48744774381165...|         2.0|\n",
            "|[9.48612103633255...|         2.0|\n",
            "|[9.48521095853561...|         2.0|\n",
            "|[18.413895,13.107...|         2.0|\n",
            "|[17.560917,13.272...|         2.0|\n",
            "|[17.419922,13.380...|         2.0|\n",
            "|[17.972828,13.549...|         2.0|\n",
            "|[9.48054395114254...|         2.0|\n",
            "|[9.47934358211962...|         2.0|\n",
            "|[16.906841,13.543...|         2.0|\n",
            "|[16.089485,13.763...|         2.0|\n",
            "|[17.893639,13.068...|         2.0|\n",
            "|[10.478089,12.935...|         2.0|\n",
            "|[18.264702,13.677...|         2.0|\n",
            "|[18.571953,13.308...|         2.0|\n",
            "|[17.599611,13.232...|         2.0|\n",
            "|[11.472302,13.474...|         2.0|\n",
            "|[9.42847816151952...|         2.0|\n",
            "+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final=data.select(\"features\",\"Status_index\")\n",
        "final.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0W9pOi77p-i"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEzBPtvP8Fzc"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'Status_index',maxIter=50, regParam=0.01, elasticNetParam=0.0)\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'Status_index')\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'Status_index',maxDepth=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9OS0Y-sC8TRR"
      },
      "outputs": [],
      "source": [
        "lrmodel = lr.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfyRxxs_8W1X"
      },
      "outputs": [],
      "source": [
        "rfModel = rf.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpVwWWdm8Z9f"
      },
      "outputs": [],
      "source": [
        "dtModel = dt.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-bZdREL8cqv"
      },
      "outputs": [],
      "source": [
        "lrmodel.save(\"lr_model\")\n",
        "rfModel.save(\"rf_model\")\n",
        "dtModel.save(\"dt__model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------------+\n",
            "|            features|Status_index|\n",
            "+--------------------+------------+\n",
            "|[7.23804924388176...|         2.0|\n",
            "+--------------------+------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebRP9PE88j94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------------+--------------------+--------------------+----------+\n",
            "|            features|Status_index|       rawPrediction|         probability|prediction|\n",
            "+--------------------+------------+--------------------+--------------------+----------+\n",
            "|[7.23804924388176...|         2.0|[1.96782387210595...|[5.32319996059868...|       2.0|\n",
            "|[7.27753040110670...|         3.0|[2.88756671123408...|[0.08350912482211...|       2.0|\n",
            "|[7.28515672754443...|         3.0|[2.91017331710185...|[0.09535542184385...|       2.0|\n",
            "+--------------------+------------+--------------------+--------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lrPrediction = lrmodel.transform(test)\n",
        "lrPrediction.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQOfiN2v8uFj"
      },
      "outputs": [],
      "source": [
        "dtPrediction = dtModel.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6ITjPm8wM2"
      },
      "outputs": [],
      "source": [
        "rfPrediction = rfModel.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D41Y6eWS8yIU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8996208190541171\n",
            "Test Error = 0.10037918094588294\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Status_index\", predictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(lrPrediction)\n",
        "print(\"Accuracy = %s\" % (accuracy))\n",
        "print(\"Test Error = %s\" % (1.0 - accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxWN17Vv82A6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9951475890391911\n",
            "Test Error = 0.004852410960808906\n"
          ]
        }
      ],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Status_index\", predictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(dtPrediction)\n",
        "print(\"Accuracy = %s\" % (accuracy))\n",
        "print(\"Test Error = %s\" % (1.0 - accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTECYeC485Pm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9951096886653021\n",
            "Test Error = 0.004890311334697861\n"
          ]
        }
      ],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Status_index\", predictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(rfPrediction)\n",
        "print(\"Accuracy = %s\" % (accuracy))\n",
        "print(\"Test Error = %s\" % (1.0 - accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6v6PcoFq87Uj",
        "outputId": "233597df-b454-44be-8e71-fd69ad13c44f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred= lrPrediction.select('prediction').collect()\n",
        "y_orig= lrPrediction.select('Status_index').collect()\n",
        "cm = confusion_matrix(y_orig,y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cGhqOj0a9ReP",
        "outputId": "bc1c3385-3842-4311-eb2d-0b903a73baca"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = \"Accuracy Score: {0}\".format(accuracy)\n",
        "plt.title(all_sample_title, size = 15);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iFFbGO9c9Rfu"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I7HXq1Pm6vtn"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NfilSGfg9RjI"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9jaUuRQL6I0B"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "siCYQ9QX7B4S"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'stream' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n stream ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spark",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "51b66f1a464c5034cedcb936140d9e3b491e586252183b49971236ca540213b5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
